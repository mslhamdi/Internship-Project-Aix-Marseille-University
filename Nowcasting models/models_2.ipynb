{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "#Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.set_visible_devices(physical_devices[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "num_cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "print(num_cpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Displaying an image from validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "tf.Tensor(\n",
      "[[[0.8901961  0.8901961  0.8901961 ]\n",
      "  [0.00980392 0.00980392 0.00980392]\n",
      "  [0.47941178 0.47941178 0.47941178]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]], shape=(64, 64, 3), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = list(val_ds)[90]\n",
    "image, label = process_img_label_val(file_path,os.path.join(\"Val_set_folder\",\"labels\"))\n",
    "\n",
    "def show(image, label):\n",
    "  plt.figure()\n",
    "  print(image.shape)\n",
    "  print(image)\n",
    "  plt.imshow(image)\n",
    "  plt.title(label.numpy())\n",
    "  plt.axis('off')\n",
    "\n",
    "show(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing and Label Normalization for Sky Camera Image Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t_scaler.pkl']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "# Create the MinMaxScaler object for target normalization\n",
    "target_scaler = MinMaxScaler()\n",
    "\n",
    "# Define paths to training and validation datasets\n",
    "train_dataset = tf.data.Dataset.list_files(\"skycamera_images - Copie/*/*\")\n",
    "val_dataset = tf.data.Dataset.list_files(\"Val_set_folder/images/*/*\")\n",
    "\n",
    "# Define the total number of samples in the training and validation datasets\n",
    "len_train = 211000\n",
    "train_per = 0.5\n",
    "len_val = 36000\n",
    "val_per = 0.5\n",
    "\n",
    "# Calculate the sizes of the training and validation datasets\n",
    "train_size = int(len_train * train_per)\n",
    "val_size = int(len_val * val_per)\n",
    "\n",
    "# Assign datasets to train_ds and val_ds\n",
    "train_ds = train_dataset\n",
    "val_ds = val_dataset\n",
    "\n",
    "# Function to get the label file path for training data\n",
    "def get_label_train(filepath, labels_folder_path):\n",
    "    time = tf.strings.split(filepath, sep=\"\\\\\")[2]\n",
    "    label_path = tf.strings.join([labels_folder_path, tf.strings.split(filepath, sep=\"\\\\\")[1], tf.strings.split(time, sep=\".\")[0] + tf.constant(\".txt\")], separator=\"\\\\\")\n",
    "    return label_path\n",
    "\n",
    "# Function to get the label file path for validation data\n",
    "def get_label_val(filepath, labels_folder_path):\n",
    "    time = tf.strings.split(filepath, sep=\"\\\\\")[3]\n",
    "    label_path = tf.strings.join([labels_folder_path, tf.strings.split(filepath, sep=\"\\\\\")[2], tf.strings.split(time, sep=\".\")[0] + tf.constant(\".txt\")], separator=\"\\\\\")\n",
    "    return label_path\n",
    "\n",
    "# Function to process image and label for validation data\n",
    "def process_img_label_val(filepath, labels_folder_path):\n",
    "    label_path = get_label_val(filepath, labels_folder_path)\n",
    "    label = tf.io.read_file(label_path)\n",
    "    label = tf.strings.to_number(label)\n",
    "    label = normalize_label(label)\n",
    "    \n",
    "    img = tf.io.read_file(filepath)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = img / 255\n",
    "    img = tf.image.resize(img, [128, 128])  # Scale and resize the image\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "# Function to process image and label for training data\n",
    "def process_img_label_train(filepath, labels_folder_path):\n",
    "    label_path = get_label_train(filepath, labels_folder_path)\n",
    "    label = tf.io.read_file(label_path)\n",
    "    label = tf.strings.to_number(label)\n",
    "    label = normalize_label(label)\n",
    "    \n",
    "    img = tf.io.read_file(filepath)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = img / 255\n",
    "    img = tf.image.resize(img, [128, 128])  # Scale and resize the image\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "# Function to normalize the label using Min-Max scaling\n",
    "def normalize_label(label):\n",
    "    label = tf.reshape(label, shape=(1, 1))  # Reshape to 2D array\n",
    "    label = target_scaler.transform(label)  # Normalize the target value\n",
    "    label = tf.squeeze(label)  # Remove extra dimensions\n",
    "    return label\n",
    "\n",
    "# Read and normalize labels for training data\n",
    "train_labels = [tf.strings.to_number(tf.io.read_file(get_label_train(filepath, \"labels_new\"))) for filepath in train_dataset]\n",
    "train_labels = tf.concat(train_labels, axis=0)\n",
    "train_labels = tf.reshape(train_labels, shape=(-1, 1))  # Reshape to 2D array\n",
    "train_labels = target_scaler.fit_transform(train_labels)  # Normalize the target values\n",
    "train_labels = tf.squeeze(train_labels)\n",
    "\n",
    "# Save the target scaler to a file\n",
    "joblib.dump(target_scaler, 't_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, label):\n",
    "    # Random rotation between -15 to 15 degrees\n",
    "    image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Pipeline Setup for Training and Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size= 128\n",
    "batch_size= 256\n",
    "\n",
    "train_ds = train_ds.map(lambda x: process_img_label_train(x,\"labels_new\"), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.cache('cachee_folder')\n",
    "train_ds = train_ds.shuffle(buffer_size=1000).batch(batch_size)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.map(lambda x: process_img_label_val(x,os.path.join(\"Val_set_folder\",\"labels\")), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(buffer_size=1000).batch(batch_size)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a custom sunset model inspired by a research paper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 8)       224       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 128, 8)      32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 16)        1168      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64, 64, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,705,137\n",
      "Trainable params: 1,704,897\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the model architecture using tf.keras API\n",
    "num_filters = 8\n",
    "kernel_size = [3,3]\n",
    "pool_size = [2,2]\n",
    "strides = 2\n",
    "dense_size = 1024\n",
    "drop_rate = 0.5\n",
    "\n",
    "\n",
    "def sunset_model():\n",
    "    ## input\n",
    "    ### input image logs with shape (64,64,24)\n",
    "    x_in = tf.keras.Input(shape=(128,128,3))\n",
    "\n",
    "    ## 1st convolution block\n",
    "    x = tf.keras.layers.Conv2D(num_filters,kernel_size,padding=\"same\",activation='relu')(x_in)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size, strides)(x)\n",
    "\n",
    "    ## 2nd convolution block\n",
    "    x = tf.keras.layers.Conv2D(num_filters*2,kernel_size,padding=\"same\",activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D([2,2], strides)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(num_filters*4,kernel_size,padding=\"same\",activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D([2,2], strides)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(num_filters*8,kernel_size,padding=\"same\",activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D([4,4], strides)(x)\n",
    "\n",
    "    ## two fully connected nets\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(drop_rate)(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(drop_rate)(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(drop_rate)(x)\n",
    "\n",
    "    ## regression to prediction target\n",
    "    y_out = tf.keras.layers.Dense(units=1,activation='linear')(x)\n",
    "\n",
    "    # construct the model\n",
    "    model = tf.keras.Model(inputs=x_in,outputs=y_out)\n",
    "    return model\n",
    "\n",
    "# show model architecture\n",
    "model=sunset_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling and training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "825/825 [==============================] - 497s 589ms/step - loss: 109.2332 - mean_absolute_error: 109.2332 - val_loss: 77.6463 - val_mean_absolute_error: 77.6463\n",
      "Epoch 2/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 77.5261 - mean_absolute_error: 77.5261 - val_loss: 52.4126 - val_mean_absolute_error: 52.4126\n",
      "Epoch 3/700\n",
      "825/825 [==============================] - 120s 145ms/step - loss: 74.1732 - mean_absolute_error: 74.1732 - val_loss: 34.3718 - val_mean_absolute_error: 34.3718\n",
      "Epoch 4/700\n",
      "825/825 [==============================] - 119s 144ms/step - loss: 72.8807 - mean_absolute_error: 72.8807 - val_loss: 35.9811 - val_mean_absolute_error: 35.9811\n",
      "Epoch 5/700\n",
      "825/825 [==============================] - 119s 144ms/step - loss: 71.8101 - mean_absolute_error: 71.8101 - val_loss: 44.3569 - val_mean_absolute_error: 44.3569\n",
      "Epoch 6/700\n",
      "825/825 [==============================] - 119s 144ms/step - loss: 71.0328 - mean_absolute_error: 71.0328 - val_loss: 35.3546 - val_mean_absolute_error: 35.3546\n",
      "Epoch 7/700\n",
      "825/825 [==============================] - 119s 144ms/step - loss: 71.0762 - mean_absolute_error: 71.0762 - val_loss: 35.2209 - val_mean_absolute_error: 35.2209\n",
      "Epoch 8/700\n",
      "825/825 [==============================] - 119s 144ms/step - loss: 70.2378 - mean_absolute_error: 70.2378 - val_loss: 38.5140 - val_mean_absolute_error: 38.5140\n",
      "Epoch 9/700\n",
      "825/825 [==============================] - 119s 143ms/step - loss: 69.4973 - mean_absolute_error: 69.4973 - val_loss: 35.7078 - val_mean_absolute_error: 35.7078\n",
      "Epoch 10/700\n",
      "825/825 [==============================] - 119s 144ms/step - loss: 69.4685 - mean_absolute_error: 69.4685 - val_loss: 46.9900 - val_mean_absolute_error: 46.9900\n",
      "Epoch 11/700\n",
      "825/825 [==============================] - 120s 145ms/step - loss: 68.8641 - mean_absolute_error: 68.8641 - val_loss: 35.4927 - val_mean_absolute_error: 35.4927\n",
      "Epoch 12/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 68.6513 - mean_absolute_error: 68.6513 - val_loss: 40.9243 - val_mean_absolute_error: 40.9243\n",
      "Epoch 13/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 68.6631 - mean_absolute_error: 68.6631 - val_loss: 42.8563 - val_mean_absolute_error: 42.8563\n",
      "Epoch 14/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 68.4051 - mean_absolute_error: 68.4051 - val_loss: 32.4139 - val_mean_absolute_error: 32.4139\n",
      "Epoch 15/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 68.1138 - mean_absolute_error: 68.1138 - val_loss: 33.0127 - val_mean_absolute_error: 33.0127\n",
      "Epoch 16/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 67.6649 - mean_absolute_error: 67.6649 - val_loss: 38.1223 - val_mean_absolute_error: 38.1223\n",
      "Epoch 17/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 67.9364 - mean_absolute_error: 67.9364 - val_loss: 34.2178 - val_mean_absolute_error: 34.2178\n",
      "Epoch 18/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 67.6361 - mean_absolute_error: 67.6361 - val_loss: 31.9353 - val_mean_absolute_error: 31.9353\n",
      "Epoch 19/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 67.6148 - mean_absolute_error: 67.6148 - val_loss: 30.3151 - val_mean_absolute_error: 30.3151\n",
      "Epoch 20/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 67.4813 - mean_absolute_error: 67.4813 - val_loss: 30.8376 - val_mean_absolute_error: 30.8376\n",
      "Epoch 21/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 67.4414 - mean_absolute_error: 67.4414 - val_loss: 59.8865 - val_mean_absolute_error: 59.8865\n",
      "Epoch 22/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 67.3964 - mean_absolute_error: 67.3964 - val_loss: 30.0513 - val_mean_absolute_error: 30.0513\n",
      "Epoch 23/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 67.1816 - mean_absolute_error: 67.1816 - val_loss: 33.7635 - val_mean_absolute_error: 33.7635\n",
      "Epoch 24/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 67.0902 - mean_absolute_error: 67.0902 - val_loss: 37.0389 - val_mean_absolute_error: 37.0389\n",
      "Epoch 25/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 67.1098 - mean_absolute_error: 67.1098 - val_loss: 37.6006 - val_mean_absolute_error: 37.6006\n",
      "Epoch 26/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 66.8972 - mean_absolute_error: 66.8972 - val_loss: 35.4918 - val_mean_absolute_error: 35.4918\n",
      "Epoch 27/700\n",
      "825/825 [==============================] - 124s 150ms/step - loss: 66.9188 - mean_absolute_error: 66.9188 - val_loss: 42.8413 - val_mean_absolute_error: 42.8413\n",
      "Epoch 28/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 66.8247 - mean_absolute_error: 66.8247 - val_loss: 29.0672 - val_mean_absolute_error: 29.0672\n",
      "Epoch 29/700\n",
      "825/825 [==============================] - 125s 151ms/step - loss: 66.7958 - mean_absolute_error: 66.7958 - val_loss: 30.1788 - val_mean_absolute_error: 30.1788\n",
      "Epoch 30/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 66.4719 - mean_absolute_error: 66.4719 - val_loss: 28.6927 - val_mean_absolute_error: 28.6927\n",
      "Epoch 31/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 66.5932 - mean_absolute_error: 66.5932 - val_loss: 29.3154 - val_mean_absolute_error: 29.3154\n",
      "Epoch 32/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 66.6826 - mean_absolute_error: 66.6826 - val_loss: 28.9435 - val_mean_absolute_error: 28.9435\n",
      "Epoch 33/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 66.4941 - mean_absolute_error: 66.4941 - val_loss: 30.1236 - val_mean_absolute_error: 30.1236\n",
      "Epoch 34/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 66.1862 - mean_absolute_error: 66.1862 - val_loss: 33.3645 - val_mean_absolute_error: 33.3645\n",
      "Epoch 35/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 66.3267 - mean_absolute_error: 66.3267 - val_loss: 31.9401 - val_mean_absolute_error: 31.9401\n",
      "Epoch 36/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 66.2250 - mean_absolute_error: 66.2250 - val_loss: 31.8596 - val_mean_absolute_error: 31.8596\n",
      "Epoch 37/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 66.2230 - mean_absolute_error: 66.2230 - val_loss: 34.2239 - val_mean_absolute_error: 34.2239\n",
      "Epoch 38/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 66.2013 - mean_absolute_error: 66.2013 - val_loss: 34.8601 - val_mean_absolute_error: 34.8601\n",
      "Epoch 39/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 66.2165 - mean_absolute_error: 66.2165 - val_loss: 33.1166 - val_mean_absolute_error: 33.1166\n",
      "Epoch 40/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 66.3199 - mean_absolute_error: 66.3199 - val_loss: 36.8148 - val_mean_absolute_error: 36.8148\n",
      "Epoch 41/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 66.0853 - mean_absolute_error: 66.0853 - val_loss: 30.9155 - val_mean_absolute_error: 30.9155\n",
      "Epoch 42/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 65.8223 - mean_absolute_error: 65.8223 - val_loss: 37.3210 - val_mean_absolute_error: 37.3210\n",
      "Epoch 43/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 65.9853 - mean_absolute_error: 65.9853 - val_loss: 35.7170 - val_mean_absolute_error: 35.7170\n",
      "Epoch 44/700\n",
      "825/825 [==============================] - 121s 147ms/step - loss: 65.8333 - mean_absolute_error: 65.8333 - val_loss: 29.1339 - val_mean_absolute_error: 29.1339\n",
      "Epoch 45/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 65.7399 - mean_absolute_error: 65.7399 - val_loss: 31.9232 - val_mean_absolute_error: 31.9232\n",
      "Epoch 46/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 65.6031 - mean_absolute_error: 65.6031 - val_loss: 32.8741 - val_mean_absolute_error: 32.8741\n",
      "Epoch 47/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 65.8088 - mean_absolute_error: 65.8088 - val_loss: 30.7254 - val_mean_absolute_error: 30.7254\n",
      "Epoch 48/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 65.6260 - mean_absolute_error: 65.6260 - val_loss: 32.5039 - val_mean_absolute_error: 32.5039\n",
      "Epoch 49/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 65.4584 - mean_absolute_error: 65.4584 - val_loss: 30.8608 - val_mean_absolute_error: 30.8608\n",
      "Epoch 50/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 65.3432 - mean_absolute_error: 65.3432 - val_loss: 30.7432 - val_mean_absolute_error: 30.7432\n",
      "Epoch 51/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 65.6347 - mean_absolute_error: 65.6347 - val_loss: 36.5149 - val_mean_absolute_error: 36.5149\n",
      "Epoch 52/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 65.4456 - mean_absolute_error: 65.4456 - val_loss: 30.3913 - val_mean_absolute_error: 30.3913\n",
      "Epoch 53/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 65.2599 - mean_absolute_error: 65.2599 - val_loss: 32.3983 - val_mean_absolute_error: 32.3983\n",
      "Epoch 54/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 65.5164 - mean_absolute_error: 65.5164 - val_loss: 36.8606 - val_mean_absolute_error: 36.8606\n",
      "Epoch 55/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 65.5127 - mean_absolute_error: 65.5127 - val_loss: 30.8880 - val_mean_absolute_error: 30.8880\n",
      "Epoch 56/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 65.0119 - mean_absolute_error: 65.0119 - val_loss: 31.6498 - val_mean_absolute_error: 31.6498\n",
      "Epoch 57/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 65.2032 - mean_absolute_error: 65.2032 - val_loss: 40.2363 - val_mean_absolute_error: 40.2363\n",
      "Epoch 58/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 65.0289 - mean_absolute_error: 65.0289 - val_loss: 31.0672 - val_mean_absolute_error: 31.0672\n",
      "Epoch 59/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 65.1437 - mean_absolute_error: 65.1437 - val_loss: 34.1320 - val_mean_absolute_error: 34.1320\n",
      "Epoch 60/700\n",
      "825/825 [==============================] - 134s 162ms/step - loss: 65.0768 - mean_absolute_error: 65.0768 - val_loss: 28.6280 - val_mean_absolute_error: 28.6280\n",
      "Epoch 61/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 65.1674 - mean_absolute_error: 65.1674 - val_loss: 31.5307 - val_mean_absolute_error: 31.5307\n",
      "Epoch 62/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 64.9560 - mean_absolute_error: 64.9560 - val_loss: 37.1684 - val_mean_absolute_error: 37.1684\n",
      "Epoch 63/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 64.9405 - mean_absolute_error: 64.9405 - val_loss: 42.8328 - val_mean_absolute_error: 42.8328\n",
      "Epoch 64/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 64.8579 - mean_absolute_error: 64.8579 - val_loss: 38.3412 - val_mean_absolute_error: 38.3412\n",
      "Epoch 65/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 64.6783 - mean_absolute_error: 64.6783 - val_loss: 29.5661 - val_mean_absolute_error: 29.5661\n",
      "Epoch 66/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 64.8081 - mean_absolute_error: 64.8081 - val_loss: 30.5083 - val_mean_absolute_error: 30.5083\n",
      "Epoch 67/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 64.8795 - mean_absolute_error: 64.8795 - val_loss: 32.5401 - val_mean_absolute_error: 32.5401\n",
      "Epoch 68/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 64.6261 - mean_absolute_error: 64.6261 - val_loss: 29.8235 - val_mean_absolute_error: 29.8235\n",
      "Epoch 69/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 64.4868 - mean_absolute_error: 64.4868 - val_loss: 29.3686 - val_mean_absolute_error: 29.3686\n",
      "Epoch 70/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 64.6363 - mean_absolute_error: 64.6363 - val_loss: 29.5853 - val_mean_absolute_error: 29.5853\n",
      "Epoch 71/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 64.5356 - mean_absolute_error: 64.5356 - val_loss: 41.1957 - val_mean_absolute_error: 41.1957\n",
      "Epoch 72/700\n",
      "825/825 [==============================] - 124s 150ms/step - loss: 64.5691 - mean_absolute_error: 64.5691 - val_loss: 29.4264 - val_mean_absolute_error: 29.4264\n",
      "Epoch 73/700\n",
      "825/825 [==============================] - 124s 150ms/step - loss: 64.5518 - mean_absolute_error: 64.5518 - val_loss: 31.1617 - val_mean_absolute_error: 31.1617\n",
      "Epoch 74/700\n",
      "825/825 [==============================] - 124s 150ms/step - loss: 64.4189 - mean_absolute_error: 64.4189 - val_loss: 28.1216 - val_mean_absolute_error: 28.1216\n",
      "Epoch 75/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 64.2824 - mean_absolute_error: 64.2824 - val_loss: 29.1182 - val_mean_absolute_error: 29.1182\n",
      "Epoch 76/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 64.4601 - mean_absolute_error: 64.4601 - val_loss: 30.6659 - val_mean_absolute_error: 30.6659\n",
      "Epoch 77/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 64.6526 - mean_absolute_error: 64.6526 - val_loss: 34.2877 - val_mean_absolute_error: 34.2877\n",
      "Epoch 78/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 64.4780 - mean_absolute_error: 64.4780 - val_loss: 29.7741 - val_mean_absolute_error: 29.7741\n",
      "Epoch 79/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 64.1704 - mean_absolute_error: 64.1704 - val_loss: 29.7729 - val_mean_absolute_error: 29.7729\n",
      "Epoch 80/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 64.3789 - mean_absolute_error: 64.3789 - val_loss: 39.2392 - val_mean_absolute_error: 39.2392\n",
      "Epoch 81/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 64.3716 - mean_absolute_error: 64.3716 - val_loss: 29.6900 - val_mean_absolute_error: 29.6900\n",
      "Epoch 82/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 64.2905 - mean_absolute_error: 64.2905 - val_loss: 29.9876 - val_mean_absolute_error: 29.9876\n",
      "Epoch 83/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 64.2130 - mean_absolute_error: 64.2130 - val_loss: 31.6846 - val_mean_absolute_error: 31.6846\n",
      "Epoch 84/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 63.9867 - mean_absolute_error: 63.9867 - val_loss: 28.9988 - val_mean_absolute_error: 28.9988\n",
      "Epoch 85/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 64.1287 - mean_absolute_error: 64.1287 - val_loss: 37.0339 - val_mean_absolute_error: 37.0339\n",
      "Epoch 86/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 64.1159 - mean_absolute_error: 64.1159 - val_loss: 33.2234 - val_mean_absolute_error: 33.2234\n",
      "Epoch 87/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 64.2789 - mean_absolute_error: 64.2789 - val_loss: 30.6449 - val_mean_absolute_error: 30.6449\n",
      "Epoch 88/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 64.1018 - mean_absolute_error: 64.1018 - val_loss: 29.4595 - val_mean_absolute_error: 29.4595\n",
      "Epoch 89/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 63.7961 - mean_absolute_error: 63.7961 - val_loss: 30.2836 - val_mean_absolute_error: 30.2836\n",
      "Epoch 90/700\n",
      "825/825 [==============================] - 124s 150ms/step - loss: 63.9317 - mean_absolute_error: 63.9317 - val_loss: 30.4054 - val_mean_absolute_error: 30.4054\n",
      "Epoch 91/700\n",
      "825/825 [==============================] - 124s 150ms/step - loss: 63.7394 - mean_absolute_error: 63.7394 - val_loss: 38.3334 - val_mean_absolute_error: 38.3334\n",
      "Epoch 92/700\n",
      "825/825 [==============================] - 124s 150ms/step - loss: 63.9391 - mean_absolute_error: 63.9391 - val_loss: 31.0354 - val_mean_absolute_error: 31.0354\n",
      "Epoch 93/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 63.8773 - mean_absolute_error: 63.8773 - val_loss: 29.1616 - val_mean_absolute_error: 29.1616\n",
      "Epoch 94/700\n",
      "825/825 [==============================] - 124s 149ms/step - loss: 64.1315 - mean_absolute_error: 64.1315 - val_loss: 30.3359 - val_mean_absolute_error: 30.3359\n",
      "Epoch 95/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 63.8885 - mean_absolute_error: 63.8885 - val_loss: 30.5264 - val_mean_absolute_error: 30.5264\n",
      "Epoch 96/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 63.7171 - mean_absolute_error: 63.7171 - val_loss: 31.3679 - val_mean_absolute_error: 31.3679\n",
      "Epoch 97/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 63.8818 - mean_absolute_error: 63.8818 - val_loss: 28.9057 - val_mean_absolute_error: 28.9057\n",
      "Epoch 98/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 63.7749 - mean_absolute_error: 63.7749 - val_loss: 29.7822 - val_mean_absolute_error: 29.7822\n",
      "Epoch 99/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.8120 - mean_absolute_error: 63.8120 - val_loss: 32.5755 - val_mean_absolute_error: 32.5755\n",
      "Epoch 100/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.7169 - mean_absolute_error: 63.7169 - val_loss: 32.0491 - val_mean_absolute_error: 32.0491\n",
      "Epoch 101/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.8934 - mean_absolute_error: 63.8934 - val_loss: 28.1790 - val_mean_absolute_error: 28.1790\n",
      "Epoch 102/700\n",
      "825/825 [==============================] - 121s 147ms/step - loss: 63.7546 - mean_absolute_error: 63.7546 - val_loss: 30.4971 - val_mean_absolute_error: 30.4971\n",
      "Epoch 103/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.7664 - mean_absolute_error: 63.7664 - val_loss: 29.7586 - val_mean_absolute_error: 29.7586\n",
      "Epoch 104/700\n",
      "825/825 [==============================] - 121s 147ms/step - loss: 63.3074 - mean_absolute_error: 63.3074 - val_loss: 29.8604 - val_mean_absolute_error: 29.8604\n",
      "Epoch 105/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.5344 - mean_absolute_error: 63.5344 - val_loss: 36.9675 - val_mean_absolute_error: 36.9675\n",
      "Epoch 106/700\n",
      "825/825 [==============================] - 121s 147ms/step - loss: 63.2220 - mean_absolute_error: 63.2220 - val_loss: 32.0437 - val_mean_absolute_error: 32.0437\n",
      "Epoch 107/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.5041 - mean_absolute_error: 63.5041 - val_loss: 29.9754 - val_mean_absolute_error: 29.9754\n",
      "Epoch 108/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.4838 - mean_absolute_error: 63.4838 - val_loss: 32.1396 - val_mean_absolute_error: 32.1396\n",
      "Epoch 109/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.4735 - mean_absolute_error: 63.4735 - val_loss: 30.3922 - val_mean_absolute_error: 30.3922\n",
      "Epoch 110/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.4390 - mean_absolute_error: 63.4390 - val_loss: 29.5250 - val_mean_absolute_error: 29.5250\n",
      "Epoch 111/700\n",
      "825/825 [==============================] - 121s 147ms/step - loss: 63.4122 - mean_absolute_error: 63.4122 - val_loss: 34.2147 - val_mean_absolute_error: 34.2147\n",
      "Epoch 112/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.2000 - mean_absolute_error: 63.2000 - val_loss: 32.8227 - val_mean_absolute_error: 32.8227\n",
      "Epoch 113/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.3797 - mean_absolute_error: 63.3797 - val_loss: 29.6773 - val_mean_absolute_error: 29.6773\n",
      "Epoch 114/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.2983 - mean_absolute_error: 63.2983 - val_loss: 28.5657 - val_mean_absolute_error: 28.5657\n",
      "Epoch 115/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.0484 - mean_absolute_error: 63.0484 - val_loss: 31.5175 - val_mean_absolute_error: 31.5175\n",
      "Epoch 116/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.2905 - mean_absolute_error: 63.2905 - val_loss: 29.9757 - val_mean_absolute_error: 29.9757\n",
      "Epoch 117/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.2789 - mean_absolute_error: 63.2789 - val_loss: 30.3087 - val_mean_absolute_error: 30.3087\n",
      "Epoch 118/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.3366 - mean_absolute_error: 63.3366 - val_loss: 30.7511 - val_mean_absolute_error: 30.7511\n",
      "Epoch 119/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 62.8966 - mean_absolute_error: 62.8966 - val_loss: 31.0990 - val_mean_absolute_error: 31.0990\n",
      "Epoch 120/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 63.1153 - mean_absolute_error: 63.1153 - val_loss: 31.6630 - val_mean_absolute_error: 31.6630\n",
      "Epoch 121/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 62.9971 - mean_absolute_error: 62.9971 - val_loss: 33.5885 - val_mean_absolute_error: 33.5885\n",
      "Epoch 122/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 63.1395 - mean_absolute_error: 63.1395 - val_loss: 28.7720 - val_mean_absolute_error: 28.7720\n",
      "Epoch 123/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 63.0919 - mean_absolute_error: 63.0919 - val_loss: 36.4334 - val_mean_absolute_error: 36.4334\n",
      "Epoch 124/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 62.9622 - mean_absolute_error: 62.9622 - val_loss: 35.3088 - val_mean_absolute_error: 35.3088\n",
      "Epoch 125/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 63.0846 - mean_absolute_error: 63.0846 - val_loss: 33.6968 - val_mean_absolute_error: 33.6968\n",
      "Epoch 126/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 62.7399 - mean_absolute_error: 62.7399 - val_loss: 29.1050 - val_mean_absolute_error: 29.1050\n",
      "Epoch 127/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 62.8215 - mean_absolute_error: 62.8215 - val_loss: 35.7221 - val_mean_absolute_error: 35.7221\n",
      "Epoch 128/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 62.8046 - mean_absolute_error: 62.8046 - val_loss: 33.0158 - val_mean_absolute_error: 33.0158\n",
      "Epoch 129/700\n",
      "825/825 [==============================] - 121s 146ms/step - loss: 62.7911 - mean_absolute_error: 62.7911 - val_loss: 34.5164 - val_mean_absolute_error: 34.5164\n",
      "Epoch 130/700\n",
      "825/825 [==============================] - 122s 147ms/step - loss: 62.9279 - mean_absolute_error: 62.9279 - val_loss: 29.8229 - val_mean_absolute_error: 29.8229\n",
      "Epoch 131/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 62.9058 - mean_absolute_error: 62.9058 - val_loss: 35.2618 - val_mean_absolute_error: 35.2618\n",
      "Epoch 132/700\n",
      "825/825 [==============================] - 123s 149ms/step - loss: 62.6207 - mean_absolute_error: 62.6207 - val_loss: 28.4115 - val_mean_absolute_error: 28.4115\n",
      "Epoch 133/700\n",
      "825/825 [==============================] - 123s 148ms/step - loss: 62.8133 - mean_absolute_error: 62.8133 - val_loss: 30.1171 - val_mean_absolute_error: 30.1171\n",
      "Epoch 134/700\n",
      "825/825 [==============================] - 122s 148ms/step - loss: 62.7082 - mean_absolute_error: 62.7082 - val_loss: 33.6360 - val_mean_absolute_error: 33.6360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25fd2c7f6a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 60, mode = 'auto'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(monitor='val_loss',mode='min',save_best_only=True,filepath=os.path.join(\"models\",'model.{epoch:02d}-{val_loss:.2f}.h5'))\n",
    "]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_absolute_error', metrics=['mean_absolute_error'], run_eagerly=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs=700\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=num_epochs,callbacks=my_callbacks,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the train and validation loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss=model.history.history['loss']\n",
    "val_loss=model.history.history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss MAE')\n",
    "plt.legend()\n",
    "plt.title('Sunset 200 000 param')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-Tuning a Pretrained ResNet50 Model with Custom Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 134, 134, 3)  0           ['input_21[0][0]']               \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 64, 64, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 64, 64, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 64, 64, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 66, 66, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 32, 32, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 32, 32, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 32, 32, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 32, 32, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 32, 32, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 32, 32, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 32, 32, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 32, 32, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 32, 32, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 32, 32, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 32, 32, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 32, 32, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 32, 32, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 32, 32, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 16, 16, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 16, 16, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 16, 16, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 16, 16, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 16, 16, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 16, 16, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 16, 16, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 16, 16, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 16, 16, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_17 (G  (None, 512)         0           ['conv3_block4_out[0][0]']       \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 256)          131328      ['global_average_pooling2d_17[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 256)          0           ['dense_60[0][0]']               \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 128)          32896       ['dropout_40[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 128)          0           ['dense_61[0][0]']               \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 1)            129         ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,624,449\n",
      "Trainable params: 1,614,337\n",
      "Non-trainable params: 10,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#We hope by using pretrained resnet model to have better performances for our regression task, it is a customed\n",
    "#model (i also modify the last layer and make the activation functiona linear one)\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "\n",
    "# Define and compile your model architecture\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False,input_shape=(128,128,3))\n",
    "\n",
    "# Freeze the first 6 layers\n",
    "#for layer in base_model.layers[:6]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of the frozen layers\n",
    "x = GlobalAveragePooling2D()(base_model.layers[-95].output)\n",
    "#y = Flatten()(x)\n",
    "z = Dense(256, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(0.01))(x)\n",
    "z = Dropout(0.4)(z)\n",
    "w = Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(0.01))(z)\n",
    "w = Dropout(0.4)(w)\n",
    "final_output = Dense(1, activation='linear')(w)\n",
    "\n",
    "# Create the modified model\n",
    "\n",
    "model_resnet=tf.keras.Model(inputs=base_model.input,outputs=final_output)\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'], run_eagerly=True)\n",
    "\n",
    "model_resnet.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling and training Resnet Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "Epoch 1/700\n",
      "1649/1649 [==============================] - 504s 305ms/step - loss: 17847.0195 - mean_squared_error: 17775.8652 - val_loss: 4391.2539 - val_mean_squared_error: 4322.3384\n",
      "Epoch 2/700\n",
      "1649/1649 [==============================] - 507s 307ms/step - loss: 7030.2847 - mean_squared_error: 6962.4478 - val_loss: 3687.8433 - val_mean_squared_error: 3621.1030\n",
      "Epoch 3/700\n",
      "1649/1649 [==============================] - 504s 306ms/step - loss: 6509.2139 - mean_squared_error: 6443.6826 - val_loss: 3896.1257 - val_mean_squared_error: 3831.8545\n",
      "Epoch 4/700\n",
      "1649/1649 [==============================] - 508s 308ms/step - loss: 6197.5259 - mean_squared_error: 6134.4209 - val_loss: 3546.9358 - val_mean_squared_error: 3485.1243\n",
      "Epoch 5/700\n",
      "1649/1649 [==============================] - 504s 306ms/step - loss: 6080.4868 - mean_squared_error: 6020.0767 - val_loss: 4050.3301 - val_mean_squared_error: 3991.4092\n",
      "Epoch 6/700\n",
      "1649/1649 [==============================] - 504s 305ms/step - loss: 5944.2842 - mean_squared_error: 5886.7363 - val_loss: 4231.8887 - val_mean_squared_error: 4175.6904\n",
      "Epoch 7/700\n",
      "1649/1649 [==============================] - 504s 306ms/step - loss: 5838.8110 - mean_squared_error: 5783.7632 - val_loss: 4482.1484 - val_mean_squared_error: 4428.1470\n",
      "Epoch 8/700\n",
      "1649/1649 [==============================] - 505s 306ms/step - loss: 5711.1235 - mean_squared_error: 5657.8423 - val_loss: 3761.2883 - val_mean_squared_error: 3708.6855\n",
      "Epoch 9/700\n",
      "1649/1649 [==============================] - 506s 307ms/step - loss: 5652.6133 - mean_squared_error: 5600.5918 - val_loss: 3474.2563 - val_mean_squared_error: 3422.7710\n",
      "Epoch 10/700\n",
      "1649/1649 [==============================] - 509s 309ms/step - loss: 5561.3945 - mean_squared_error: 5510.3262 - val_loss: 4484.9028 - val_mean_squared_error: 4434.2988\n",
      "Epoch 11/700\n",
      "1649/1649 [==============================] - 509s 309ms/step - loss: 5435.5874 - mean_squared_error: 5385.3384 - val_loss: 4658.9170 - val_mean_squared_error: 4609.0376\n",
      "Epoch 12/700\n",
      "1649/1649 [==============================] - 509s 309ms/step - loss: 5349.7051 - mean_squared_error: 5300.1201 - val_loss: 3783.3960 - val_mean_squared_error: 3734.1287\n",
      "Epoch 13/700\n",
      "1649/1649 [==============================] - 510s 309ms/step - loss: 5280.7876 - mean_squared_error: 5231.7583 - val_loss: 3398.1846 - val_mean_squared_error: 3349.4351\n",
      "Epoch 14/700\n",
      "1649/1649 [==============================] - 502s 304ms/step - loss: 5210.0601 - mean_squared_error: 5161.4858 - val_loss: 3677.2668 - val_mean_squared_error: 3628.8586\n",
      "Epoch 15/700\n",
      "1649/1649 [==============================] - 501s 304ms/step - loss: 5165.3457 - mean_squared_error: 5117.0659 - val_loss: 3449.6475 - val_mean_squared_error: 3401.5066\n",
      "Epoch 16/700\n",
      "1649/1649 [==============================] - 501s 303ms/step - loss: 5106.9556 - mean_squared_error: 5058.8965 - val_loss: 3660.5693 - val_mean_squared_error: 3612.6260\n",
      "Epoch 17/700\n",
      "1649/1649 [==============================] - 499s 303ms/step - loss: 5075.4990 - mean_squared_error: 5027.6504 - val_loss: 3594.3582 - val_mean_squared_error: 3546.6406\n",
      "Epoch 18/700\n",
      "1649/1649 [==============================] - 501s 304ms/step - loss: 4989.8848 - mean_squared_error: 4942.3081 - val_loss: 3462.1682 - val_mean_squared_error: 3414.7527\n",
      "Epoch 19/700\n",
      "1649/1649 [==============================] - 510s 309ms/step - loss: 4912.6221 - mean_squared_error: 4865.3599 - val_loss: 3924.4211 - val_mean_squared_error: 3877.3230\n",
      "Epoch 20/700\n",
      "1649/1649 [==============================] - 505s 306ms/step - loss: 4877.3643 - mean_squared_error: 4830.3486 - val_loss: 3620.3328 - val_mean_squared_error: 3573.4631\n",
      "Epoch 21/700\n",
      "1649/1649 [==============================] - 504s 305ms/step - loss: 4834.7515 - mean_squared_error: 4787.9839 - val_loss: 3548.7551 - val_mean_squared_error: 3502.1348\n",
      "Epoch 22/700\n",
      "1649/1649 [==============================] - 503s 305ms/step - loss: 4792.0796 - mean_squared_error: 4745.5532 - val_loss: 3504.0300 - val_mean_squared_error: 3457.5706\n",
      "Epoch 23/700\n",
      " 557/1649 [=========>....................] - ETA: 5:01 - loss: 4748.0518 - mean_squared_error: 4701.6006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13836\\266692912.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Fit the model and record the loss values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                 \u001b[1;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 )\n\u001b[0;32m   1145\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m             outputs = reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"first\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1313\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1314\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1315\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3690\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3691\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3692\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3694\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m                 \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    991\u001b[0m         \u001b[1;31m# Run forward pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 993\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    994\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1095\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 ):\n\u001b[1;32m-> 1097\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_keras_call_info_injected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \"\"\"\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1095\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 ):\n\u001b[1;32m-> 1097\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_keras_call_info_injected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m                 \u001b[1;31m# Currently never reaches here since fused_batch_norm does not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    715\u001b[0m                     )\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_update\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance_update\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_update\u001b[1;34m(self, updates)\u001b[0m\n\u001b[0;32m   1689\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1691\u001b[1;33m                     \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\u001b[0m in \u001b[0;36mmean_update\u001b[1;34m()\u001b[0m\n\u001b[0;32m    686\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                         \u001b[0mnew_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_new_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoving_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m                     return self._assign_moving_average(\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\u001b[0m in \u001b[0;36m_assign_new_value\u001b[1;34m(self, variable, value)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AssignNewValue\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"validate_shape\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[1;32m--> 942\u001b[1;33m           self.handle, value_tensor, name=name, **kwargs)\n\u001b[0m\u001b[0;32m    943\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[1;34m(resource, value, validate_shape, name)\u001b[0m\n\u001b[0;32m    141\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m    142\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"AssignVariableOp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"validate_shape\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         validate_shape)\n\u001b[0m\u001b[0;32m    144\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#The training operation was done many times not only one time (the terminal contains the result of the last one)\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 140, mode = 'auto'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(monitor='val_loss',mode='min',save_best_only=True,filepath=os.path.join(\"models\",'model.{epoch:02d}-{val_loss:.2f}.h5'))\n",
    "]\n",
    "\n",
    "model_resnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mean_squared_error'], run_eagerly=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs=700\n",
    "\n",
    "#model=tf.keras.models.load_model(\"models\\\\model.03-3695.77.h5\")\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "    \n",
    "    # Fit the model and record the loss values\n",
    "    history = model_resnet.fit(train_ds, validation_data=val_ds, epochs=num_epochs,callbacks=my_callbacks,verbose=1)\n",
    "    train_loss.append(history.history['loss'])\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    \n",
    "    # Print the loss for the current epoch\n",
    "    print('Train Loss: {:.4f}'.format(train_loss[-1]))\n",
    "    print('Val Loss: {:.4f}'.format(val_loss[-1]))\n",
    "\n",
    "    np.save('my_history.npy',model.history)\n",
    "    \n",
    "    # Plot the loss evolution\n",
    "    plt.plot(np.arange(epoch+1), train_loss, label='Train Loss')\n",
    "    plt.plot(np.arange(epoch+1), val_loss, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#with open('training_history.pkl', 'wb') as file:\n",
    "#    pickle.dump(model.history, file)\n",
    "model_resnet.save(os.path.join('models','last_epoch_model.h5'))\n",
    "\n",
    "np.save('my_history.npy',model_resnet.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-tuning first VGG16 Model to do a regression task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, None, 1)     513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 14,715,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# Define and compile your model architecture\n",
    "\n",
    "model=tf.keras.applications.VGG16(include_top=False)\n",
    "\n",
    "model_input=model.layers[0].input #acces to the input of the first layer\n",
    "model_output=model.layers[-2].output #acces to the output of the layer model.layers[-2]\n",
    "final_output=Dense(1,activation=\"linear\")(model_output)\n",
    "\n",
    "model=tf.keras.Model(inputs=model_input,outputs=final_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'], run_eagerly=True)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#The model is not good at all because in the last layers, we move from a block of conv layers to directly one neuron of dense layer\n",
    "#with a linear activation function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-Tuning a second Pretrained VGG16 Model with Custom Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,751,169\n",
      "Trainable params: 1,115,905\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#We hope by using pretrained resnet model to have better performances for our regression task, it is a customed\n",
    "#model (i also modify the last layer and make the activation functiona linear one)\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# Define and compile your model architecture\n",
    "\n",
    "model=tf.keras.applications.VGG16(weights='imagenet', include_top=False,input_shape=(64,64,3))\n",
    "\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_input=model.layers[0].input #acces to the input of the first layer\n",
    "model_output=model.layers[-5].output #acces to the output of the layer model.layers[-2]\n",
    "fin=GlobalAveragePooling2D()(model_output)\n",
    "finn=Dense(1024,activation=\"relu\")(fin)\n",
    "z = Dropout(0.4)(finn)\n",
    "finm=Dense(512,activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l1(0.01))(z)\n",
    "w= Dropout(0.4)(finm)\n",
    "final=Dense(128,activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l1(0.001))(w)\n",
    "final_output=Dense(1,activation=\"linear\")(final)\n",
    "\n",
    "model_vgg=tf.keras.Model(inputs=model_input,outputs=final_output)\n",
    "\n",
    "# Compile the model\n",
    "model_vgg.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'], run_eagerly=True)\n",
    "\n",
    "model_vgg.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling anf training VGG model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "825/825 [==============================] - 1476s 2s/step - loss: 30779.3027 - mean_squared_error: 30653.2363 - val_loss: 8355.5352 - val_mean_squared_error: 8244.0596\n",
      "Epoch 2/700\n",
      "825/825 [==============================] - 225s 273ms/step - loss: 9107.3750 - mean_squared_error: 8996.6436 - val_loss: 6786.8701 - val_mean_squared_error: 6676.6587\n",
      "Epoch 3/700\n",
      "825/825 [==============================] - 226s 273ms/step - loss: 8040.0874 - mean_squared_error: 7930.3970 - val_loss: 6269.4019 - val_mean_squared_error: 6160.0972\n",
      "Epoch 4/700\n",
      "825/825 [==============================] - 225s 272ms/step - loss: 7392.1538 - mean_squared_error: 7283.2637 - val_loss: 5979.7212 - val_mean_squared_error: 5871.1978\n",
      "Epoch 5/700\n",
      "825/825 [==============================] - 227s 275ms/step - loss: 7036.9702 - mean_squared_error: 6928.9170 - val_loss: 5845.3442 - val_mean_squared_error: 5737.6411\n",
      "Epoch 6/700\n",
      "825/825 [==============================] - 229s 278ms/step - loss: 6787.4771 - mean_squared_error: 6680.1382 - val_loss: 6044.4321 - val_mean_squared_error: 5937.3950\n",
      "Epoch 7/700\n",
      "825/825 [==============================] - 230s 278ms/step - loss: 6601.3999 - mean_squared_error: 6494.6548 - val_loss: 5514.8242 - val_mean_squared_error: 5408.2832\n",
      "Epoch 8/700\n",
      "825/825 [==============================] - 229s 277ms/step - loss: 6457.0503 - mean_squared_error: 6350.6587 - val_loss: 5522.9561 - val_mean_squared_error: 5416.5723\n",
      "Epoch 9/700\n",
      "825/825 [==============================] - 230s 279ms/step - loss: 6322.5488 - mean_squared_error: 6216.2095 - val_loss: 5645.9629 - val_mean_squared_error: 5539.6138\n",
      "Epoch 10/700\n",
      "825/825 [==============================] - 231s 280ms/step - loss: 6231.5449 - mean_squared_error: 6125.0840 - val_loss: 5253.2842 - val_mean_squared_error: 5146.6504\n",
      "Epoch 11/700\n",
      "825/825 [==============================] - 230s 278ms/step - loss: 6115.6396 - mean_squared_error: 6008.8516 - val_loss: 5235.1709 - val_mean_squared_error: 5128.1992\n",
      "Epoch 12/700\n",
      "825/825 [==============================] - 230s 279ms/step - loss: 6033.4487 - mean_squared_error: 5926.3174 - val_loss: 5188.7021 - val_mean_squared_error: 5081.2549\n",
      "Epoch 13/700\n",
      "825/825 [==============================] - 229s 278ms/step - loss: 5980.7354 - mean_squared_error: 5873.0874 - val_loss: 5120.2046 - val_mean_squared_error: 5012.2749\n",
      "Epoch 14/700\n",
      "825/825 [==============================] - 228s 275ms/step - loss: 5918.8945 - mean_squared_error: 5810.7310 - val_loss: 5116.1416 - val_mean_squared_error: 5007.6523\n",
      "Epoch 15/700\n",
      "192/825 [=====>........................] - ETA: 2:42 - loss: 5824.1372 - mean_squared_error: 5715.6362"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21696\\3607170374.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m700\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                 \u001b[1;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 )\n\u001b[0;32m   1145\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m             outputs = reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"first\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1313\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1314\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1315\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3690\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3691\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3692\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3694\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m                 \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    995\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[1;31m# Run backwards pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    998\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    575\u001b[0m         \"\"\"\n\u001b[0;32m    576\u001b[0m         grads_and_vars = self._compute_gradients(\n\u001b[1;32m--> 577\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m         )\n\u001b[0;32m    579\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/gradients\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             grads_and_vars = self._get_gradients(\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m             )\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1117\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    158\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     if skip_input_indices is not None and 1 in skip_input_indices and _IsScalar(\n\u001b[0;32m   1356\u001b[0m         y):\n\u001b[1;32m-> 1357\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m     \u001b[1;31m# No gradient skipping, so do the full gradient computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6574\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6575\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 6576\u001b[1;33m         _ctx, \"Mul\", name, x, y)\n\u001b[0m\u001b[0;32m   6577\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6578\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 200, mode = 'auto'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(monitor='val_loss',mode='min',save_best_only=True,filepath=os.path.join(\"models\",'model.{epoch:02d}-{val_loss:.2f}.h5'))\n",
    "]\n",
    "\n",
    "model_vgg.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mean_squared_error'], run_eagerly=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs=700\n",
    "\n",
    "model_vgg.fit(train_ds, validation_data=val_ds, epochs=num_epochs,callbacks=my_callbacks,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.save(\"vgg_with_frozen_layers.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss=model_vgg.history.history['loss'] #MAE\n",
    "val_loss=model_vgg.history.history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Vgg16 transfer learning')\n",
    "plt.show()\n",
    "\n",
    "#The model is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "Epoch 1/700\n",
      "1649/1649 [==============================] - 653s 396ms/step - loss: 3709.0986 - mean_squared_error: 3709.0986 - val_loss: 125605.0781 - val_mean_squared_error: 125605.0781\n",
      "Epoch 2/700\n",
      "1649/1649 [==============================] - 652s 394ms/step - loss: 3203.6172 - mean_squared_error: 3203.6172 - val_loss: 285141.4062 - val_mean_squared_error: 285141.4062\n",
      "Epoch 3/700\n",
      "1649/1649 [==============================] - 642s 389ms/step - loss: 3001.7017 - mean_squared_error: 3001.7017 - val_loss: 453067.5000 - val_mean_squared_error: 453067.5000\n",
      "Epoch 4/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 2761.5176 - mean_squared_error: 2761.5176 - val_loss: 121450.5547 - val_mean_squared_error: 121450.5547\n",
      "Epoch 5/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 2465.9949 - mean_squared_error: 2465.9949 - val_loss: 116499.5000 - val_mean_squared_error: 116499.5000\n",
      "Epoch 6/700\n",
      "1649/1649 [==============================] - 651s 394ms/step - loss: 2227.8452 - mean_squared_error: 2227.8452 - val_loss: 2663452.0000 - val_mean_squared_error: 2663452.0000\n",
      "Epoch 7/700\n",
      "1649/1649 [==============================] - 655s 396ms/step - loss: 2031.6409 - mean_squared_error: 2031.6409 - val_loss: 1465741.3750 - val_mean_squared_error: 1465741.3750\n",
      "Epoch 8/700\n",
      "1649/1649 [==============================] - 649s 392ms/step - loss: 1843.2079 - mean_squared_error: 1843.2079 - val_loss: 2044110.7500 - val_mean_squared_error: 2044110.7500\n",
      "Epoch 9/700\n",
      "1649/1649 [==============================] - 652s 394ms/step - loss: 1681.9846 - mean_squared_error: 1681.9846 - val_loss: 5383206.5000 - val_mean_squared_error: 5383206.5000\n",
      "Epoch 10/700\n",
      "1649/1649 [==============================] - 654s 396ms/step - loss: 1542.1958 - mean_squared_error: 1542.1958 - val_loss: 1622807.3750 - val_mean_squared_error: 1622807.3750\n",
      "Epoch 11/700\n",
      "1649/1649 [==============================] - 656s 397ms/step - loss: 1414.8301 - mean_squared_error: 1414.8301 - val_loss: 6457908.0000 - val_mean_squared_error: 6457908.0000\n",
      "Epoch 12/700\n",
      "1649/1649 [==============================] - 654s 396ms/step - loss: 1318.9481 - mean_squared_error: 1318.9481 - val_loss: 13625994.0000 - val_mean_squared_error: 13625994.0000\n",
      "Epoch 13/700\n",
      "1649/1649 [==============================] - 643s 389ms/step - loss: 1236.0009 - mean_squared_error: 1236.0009 - val_loss: 227787.3438 - val_mean_squared_error: 227787.3438\n",
      "Epoch 14/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 1177.2059 - mean_squared_error: 1177.2059 - val_loss: 16425900.0000 - val_mean_squared_error: 16425900.0000\n",
      "Epoch 15/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 1109.1638 - mean_squared_error: 1109.1638 - val_loss: 9436299.0000 - val_mean_squared_error: 9436299.0000\n",
      "Epoch 16/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 1041.9906 - mean_squared_error: 1041.9906 - val_loss: 29104310.0000 - val_mean_squared_error: 29104310.0000\n",
      "Epoch 17/700\n",
      "1649/1649 [==============================] - 652s 394ms/step - loss: 1009.6209 - mean_squared_error: 1009.6209 - val_loss: 16743748.0000 - val_mean_squared_error: 16743748.0000\n",
      "Epoch 18/700\n",
      "1649/1649 [==============================] - 645s 390ms/step - loss: 956.6909 - mean_squared_error: 956.6909 - val_loss: 25194204.0000 - val_mean_squared_error: 25194204.0000\n",
      "Epoch 19/700\n",
      "1649/1649 [==============================] - 651s 394ms/step - loss: 881.7540 - mean_squared_error: 881.7540 - val_loss: 24373996.0000 - val_mean_squared_error: 24373996.0000\n",
      "Epoch 20/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 862.2020 - mean_squared_error: 862.2020 - val_loss: 14329758.0000 - val_mean_squared_error: 14329758.0000\n",
      "Epoch 21/700\n",
      "1649/1649 [==============================] - 652s 394ms/step - loss: 819.1235 - mean_squared_error: 819.1235 - val_loss: 14289762.0000 - val_mean_squared_error: 14289762.0000\n",
      "Epoch 22/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 787.3448 - mean_squared_error: 787.3448 - val_loss: 38634088.0000 - val_mean_squared_error: 38634088.0000\n",
      "Epoch 23/700\n",
      "1649/1649 [==============================] - 643s 389ms/step - loss: 757.3286 - mean_squared_error: 757.3286 - val_loss: 26344962.0000 - val_mean_squared_error: 26344962.0000\n",
      "Epoch 24/700\n",
      "1649/1649 [==============================] - 657s 397ms/step - loss: 722.6906 - mean_squared_error: 722.6906 - val_loss: 20173344.0000 - val_mean_squared_error: 20173344.0000\n",
      "Epoch 25/700\n",
      "1649/1649 [==============================] - 658s 398ms/step - loss: 692.7112 - mean_squared_error: 692.7112 - val_loss: 28564662.0000 - val_mean_squared_error: 28564662.0000\n",
      "Epoch 26/700\n",
      "1649/1649 [==============================] - 658s 398ms/step - loss: 693.5345 - mean_squared_error: 693.5345 - val_loss: 13750785.0000 - val_mean_squared_error: 13750785.0000\n",
      "Epoch 27/700\n",
      "1649/1649 [==============================] - 658s 398ms/step - loss: 624.7024 - mean_squared_error: 624.7024 - val_loss: 22972874.0000 - val_mean_squared_error: 22972874.0000\n",
      "Epoch 28/700\n",
      "1649/1649 [==============================] - 656s 397ms/step - loss: 596.1523 - mean_squared_error: 596.1523 - val_loss: 764572.7500 - val_mean_squared_error: 764572.7500\n",
      "Epoch 29/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 618.0778 - mean_squared_error: 618.0778 - val_loss: 5094249.5000 - val_mean_squared_error: 5094249.5000\n",
      "Epoch 30/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 571.1437 - mean_squared_error: 571.1437 - val_loss: 3058873.5000 - val_mean_squared_error: 3058873.5000\n",
      "Epoch 31/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 636.1398 - mean_squared_error: 636.1398 - val_loss: 939489.7500 - val_mean_squared_error: 939489.7500\n",
      "Epoch 32/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 511.8199 - mean_squared_error: 511.8199 - val_loss: 11963051.0000 - val_mean_squared_error: 11963051.0000\n",
      "Epoch 33/700\n",
      "1649/1649 [==============================] - 643s 389ms/step - loss: 549.5552 - mean_squared_error: 549.5552 - val_loss: 6128311.0000 - val_mean_squared_error: 6128311.0000\n",
      "Epoch 34/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 513.6284 - mean_squared_error: 513.6284 - val_loss: 101488496.0000 - val_mean_squared_error: 101488496.0000\n",
      "Epoch 35/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 586.1498 - mean_squared_error: 586.1498 - val_loss: 27674990.0000 - val_mean_squared_error: 27674990.0000\n",
      "Epoch 36/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 479.5453 - mean_squared_error: 479.5453 - val_loss: 4572882.5000 - val_mean_squared_error: 4572882.5000\n",
      "Epoch 37/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 418.7337 - mean_squared_error: 418.7337 - val_loss: 24988420.0000 - val_mean_squared_error: 24988420.0000\n",
      "Epoch 38/700\n",
      "1649/1649 [==============================] - 646s 391ms/step - loss: 425.6170 - mean_squared_error: 425.6170 - val_loss: 41149780.0000 - val_mean_squared_error: 41149780.0000\n",
      "Epoch 39/700\n",
      "1649/1649 [==============================] - 652s 394ms/step - loss: 493.5790 - mean_squared_error: 493.5790 - val_loss: 55737248.0000 - val_mean_squared_error: 55737248.0000\n",
      "Epoch 40/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 470.9330 - mean_squared_error: 470.9330 - val_loss: 22261822.0000 - val_mean_squared_error: 22261822.0000\n",
      "Epoch 41/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 396.5140 - mean_squared_error: 396.5140 - val_loss: 24675322.0000 - val_mean_squared_error: 24675322.0000\n",
      "Epoch 42/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 393.5724 - mean_squared_error: 393.5724 - val_loss: 69036896.0000 - val_mean_squared_error: 69036896.0000\n",
      "Epoch 43/700\n",
      "1649/1649 [==============================] - 648s 392ms/step - loss: 432.9031 - mean_squared_error: 432.9031 - val_loss: 30112634.0000 - val_mean_squared_error: 30112634.0000\n",
      "Epoch 44/700\n",
      "1649/1649 [==============================] - 656s 397ms/step - loss: 405.9566 - mean_squared_error: 405.9566 - val_loss: 18434816.0000 - val_mean_squared_error: 18434816.0000\n",
      "Epoch 45/700\n",
      "1649/1649 [==============================] - 658s 398ms/step - loss: 384.2598 - mean_squared_error: 384.2598 - val_loss: 17264520.0000 - val_mean_squared_error: 17264520.0000\n",
      "Epoch 46/700\n",
      "1649/1649 [==============================] - 654s 396ms/step - loss: 373.3573 - mean_squared_error: 373.3573 - val_loss: 21613752.0000 - val_mean_squared_error: 21613752.0000\n",
      "Epoch 47/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 357.3028 - mean_squared_error: 357.3028 - val_loss: 28847948.0000 - val_mean_squared_error: 28847948.0000\n",
      "Epoch 48/700\n",
      "1649/1649 [==============================] - 646s 391ms/step - loss: 384.8818 - mean_squared_error: 384.8818 - val_loss: 33482858.0000 - val_mean_squared_error: 33482858.0000\n",
      "Epoch 49/700\n",
      "1649/1649 [==============================] - 643s 389ms/step - loss: 355.6641 - mean_squared_error: 355.6641 - val_loss: 60331224.0000 - val_mean_squared_error: 60331224.0000\n",
      "Epoch 50/700\n",
      "1649/1649 [==============================] - 640s 387ms/step - loss: 336.0526 - mean_squared_error: 336.0526 - val_loss: 21645880.0000 - val_mean_squared_error: 21645880.0000\n",
      "Epoch 51/700\n",
      "1649/1649 [==============================] - 649s 393ms/step - loss: 364.0503 - mean_squared_error: 364.0503 - val_loss: 18598674.0000 - val_mean_squared_error: 18598674.0000\n",
      "Epoch 52/700\n",
      "1649/1649 [==============================] - 646s 391ms/step - loss: 399.9679 - mean_squared_error: 399.9679 - val_loss: 53864980.0000 - val_mean_squared_error: 53864980.0000\n",
      "Epoch 53/700\n",
      "1649/1649 [==============================] - 638s 386ms/step - loss: 317.2884 - mean_squared_error: 317.2884 - val_loss: 10195300.0000 - val_mean_squared_error: 10195300.0000\n",
      "Epoch 54/700\n",
      "1649/1649 [==============================] - 645s 391ms/step - loss: 260.6624 - mean_squared_error: 260.6624 - val_loss: 26768810.0000 - val_mean_squared_error: 26768810.0000\n",
      "Epoch 55/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 367.3016 - mean_squared_error: 367.3016 - val_loss: 21920294.0000 - val_mean_squared_error: 21920294.0000\n",
      "Epoch 56/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 289.0446 - mean_squared_error: 289.0446 - val_loss: 14557650.0000 - val_mean_squared_error: 14557650.0000\n",
      "Epoch 57/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 247.1110 - mean_squared_error: 247.1110 - val_loss: 12746998.0000 - val_mean_squared_error: 12746998.0000\n",
      "Epoch 58/700\n",
      "1649/1649 [==============================] - 645s 390ms/step - loss: 218.4302 - mean_squared_error: 218.4302 - val_loss: 26856342.0000 - val_mean_squared_error: 26856342.0000\n",
      "Epoch 59/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 358.6749 - mean_squared_error: 358.6749 - val_loss: 70563456.0000 - val_mean_squared_error: 70563456.0000\n",
      "Epoch 60/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 324.0015 - mean_squared_error: 324.0015 - val_loss: 93250624.0000 - val_mean_squared_error: 93250624.0000\n",
      "Epoch 61/700\n",
      "1649/1649 [==============================] - 650s 393ms/step - loss: 273.4775 - mean_squared_error: 273.4775 - val_loss: 5932637.0000 - val_mean_squared_error: 5932637.0000\n",
      "Epoch 62/700\n",
      "1649/1649 [==============================] - 648s 392ms/step - loss: 201.1235 - mean_squared_error: 201.1235 - val_loss: 15935058.0000 - val_mean_squared_error: 15935058.0000\n",
      "Epoch 63/700\n",
      "1649/1649 [==============================] - 639s 387ms/step - loss: 204.5301 - mean_squared_error: 204.5301 - val_loss: 103638384.0000 - val_mean_squared_error: 103638384.0000\n",
      "Epoch 64/700\n",
      "1649/1649 [==============================] - 645s 391ms/step - loss: 289.9895 - mean_squared_error: 289.9895 - val_loss: 19013414.0000 - val_mean_squared_error: 19013414.0000\n",
      "Epoch 65/700\n",
      "1649/1649 [==============================] - 644s 390ms/step - loss: 235.6836 - mean_squared_error: 235.6836 - val_loss: 10792057.0000 - val_mean_squared_error: 10792057.0000\n",
      "Epoch 66/700\n",
      "1649/1649 [==============================] - 643s 390ms/step - loss: 227.3365 - mean_squared_error: 227.3365 - val_loss: 42198004.0000 - val_mean_squared_error: 42198004.0000\n",
      "Epoch 67/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 291.1355 - mean_squared_error: 291.1355 - val_loss: 11659431.0000 - val_mean_squared_error: 11659431.0000\n",
      "Epoch 68/700\n",
      "1649/1649 [==============================] - 645s 391ms/step - loss: 240.2662 - mean_squared_error: 240.2662 - val_loss: 38937652.0000 - val_mean_squared_error: 38937652.0000\n",
      "Epoch 69/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 192.0113 - mean_squared_error: 192.0113 - val_loss: 46064956.0000 - val_mean_squared_error: 46064956.0000\n",
      "Epoch 70/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 317.2556 - mean_squared_error: 317.2556 - val_loss: 67452408.0000 - val_mean_squared_error: 67452408.0000\n",
      "Epoch 71/700\n",
      "1649/1649 [==============================] - 652s 394ms/step - loss: 244.6849 - mean_squared_error: 244.6849 - val_loss: 8469592.0000 - val_mean_squared_error: 8469592.0000\n",
      "Epoch 72/700\n",
      "1649/1649 [==============================] - 646s 391ms/step - loss: 184.8917 - mean_squared_error: 184.8917 - val_loss: 96903200.0000 - val_mean_squared_error: 96903200.0000\n",
      "Epoch 73/700\n",
      "1649/1649 [==============================] - 639s 387ms/step - loss: 224.0832 - mean_squared_error: 224.0832 - val_loss: 7338243.5000 - val_mean_squared_error: 7338243.5000\n",
      "Epoch 74/700\n",
      "1649/1649 [==============================] - 646s 391ms/step - loss: 180.1502 - mean_squared_error: 180.1502 - val_loss: 2861383.0000 - val_mean_squared_error: 2861383.0000\n",
      "Epoch 75/700\n",
      "1649/1649 [==============================] - 645s 391ms/step - loss: 196.9687 - mean_squared_error: 196.9687 - val_loss: 35683748.0000 - val_mean_squared_error: 35683748.0000\n",
      "Epoch 76/700\n",
      "1649/1649 [==============================] - 644s 390ms/step - loss: 260.0883 - mean_squared_error: 260.0883 - val_loss: 39909984.0000 - val_mean_squared_error: 39909984.0000\n",
      "Epoch 77/700\n",
      "1649/1649 [==============================] - 655s 396ms/step - loss: 252.2113 - mean_squared_error: 252.2113 - val_loss: 46803308.0000 - val_mean_squared_error: 46803308.0000\n",
      "Epoch 78/700\n",
      "1649/1649 [==============================] - 649s 392ms/step - loss: 228.8308 - mean_squared_error: 228.8308 - val_loss: 260007.8281 - val_mean_squared_error: 260007.8281\n",
      "Epoch 79/700\n",
      "1649/1649 [==============================] - 653s 395ms/step - loss: 232.0701 - mean_squared_error: 232.0701 - val_loss: 2914220.5000 - val_mean_squared_error: 2914220.5000\n",
      "Epoch 80/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 143.9062 - mean_squared_error: 143.9062 - val_loss: 1876691.5000 - val_mean_squared_error: 1876691.5000\n",
      "Epoch 81/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 122.9893 - mean_squared_error: 122.9893 - val_loss: 39849400.0000 - val_mean_squared_error: 39849400.0000\n",
      "Epoch 82/700\n",
      "1649/1649 [==============================] - 652s 395ms/step - loss: 211.6190 - mean_squared_error: 211.6190 - val_loss: 8102721.5000 - val_mean_squared_error: 8102721.5000\n",
      "Epoch 83/700\n",
      "1649/1649 [==============================] - 643s 389ms/step - loss: 218.7525 - mean_squared_error: 218.7525 - val_loss: 14887581.0000 - val_mean_squared_error: 14887581.0000\n",
      "Epoch 84/700\n",
      "1649/1649 [==============================] - 646s 391ms/step - loss: 172.1752 - mean_squared_error: 172.1752 - val_loss: 10496731.0000 - val_mean_squared_error: 10496731.0000\n",
      "Epoch 85/700\n",
      "1649/1649 [==============================] - 645s 391ms/step - loss: 183.3464 - mean_squared_error: 183.3464 - val_loss: 33462316.0000 - val_mean_squared_error: 33462316.0000\n",
      "Epoch 86/700\n",
      "1649/1649 [==============================] - 645s 390ms/step - loss: 229.7322 - mean_squared_error: 229.7322 - val_loss: 24520720.0000 - val_mean_squared_error: 24520720.0000\n",
      "Epoch 87/700\n",
      "1649/1649 [==============================] - 647s 391ms/step - loss: 174.8434 - mean_squared_error: 174.8434 - val_loss: 5062078.5000 - val_mean_squared_error: 5062078.5000\n",
      "Epoch 88/700\n",
      "1649/1649 [==============================] - 642s 389ms/step - loss: 133.3362 - mean_squared_error: 133.3362 - val_loss: 5279759.5000 - val_mean_squared_error: 5279759.5000\n",
      "Epoch 89/700\n",
      "1644/1649 [============================>.] - ETA: 1s - loss: 135.5015 - mean_squared_error: 135.5015"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7140\\942555597.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Fit the model and record the loss values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                 \u001b[1;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 )\n\u001b[0;32m   1145\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m             outputs = reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"first\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1313\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1314\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1315\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3690\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3691\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3692\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3694\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m                 \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    992\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[1;31m# Run backwards pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mx\u001b[0m  \u001b[1;31m# The default implementation does not use `x`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m         return self.compiled_loss(\n\u001b[1;32m-> 1053\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization_losses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m         )\n\u001b[0;32m   1055\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\compile_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m             \u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch_dtype_and_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m             \u001b[0msw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\compile_utils.py\u001b[0m in \u001b[0;36mmatch_dtype_and_rank\u001b[1;34m(y_t, y_p, sw)\u001b[0m\n\u001b[0;32m    830\u001b[0m     \u001b[1;34m\"\"\"Match dtype and rank of predictions.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 832\u001b[1;33m         \u001b[0my_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    833\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msw\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mexpand_dims_v2\u001b[1;34m(input, axis, name)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[0mInvalidArgumentError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m   \"\"\"\n\u001b[1;32m--> 442\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[1;34m(input, axis, name)\u001b[0m\n\u001b[0;32m   2343\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2344\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 2345\u001b[1;33m         _ctx, \"ExpandDims\", name, input, axis)\n\u001b[0m\u001b[0;32m   2346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2347\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=model_vgg\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 140, mode = 'auto'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(monitor='val_loss',mode='min',save_best_only=True,filepath=os.path.join(\"models\",'model.{epoch:02d}-{val_loss:.2f}.h5'))\n",
    "]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mean_squared_error'], run_eagerly=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs=700\n",
    "\n",
    "#model=tf.keras.models.load_model(\"models\\\\model.03-3695.77.h5\")\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "    \n",
    "    # Fit the model and record the loss values\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=num_epochs,callbacks=my_callbacks,verbose=1)\n",
    "    train_loss.append(history.history['loss'])\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    \n",
    "    # Print the loss for the current epoch\n",
    "    print('Train Loss: {:.4f}'.format(train_loss[-1]))\n",
    "    print('Val Loss: {:.4f}'.format(val_loss[-1]))\n",
    "\n",
    "    np.save('my_history.npy',model.history)\n",
    "    \n",
    "    # Plot the loss evolution\n",
    "    plt.plot(np.arange(epoch+1), train_loss, label='Train Loss')\n",
    "    plt.plot(np.arange(epoch+1), val_loss, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#with open('training_history.pkl', 'wb') as file:\n",
    "#    pickle.dump(model.history, file)\n",
    "model.save(os.path.join('models','last_epoch_model.h5'))\n",
    "\n",
    "np.save('my_history.npy',model.history)\n",
    "\n",
    "#THE MODEL IS LCEARLY OVER-FITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, None, 1)     513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 14,715,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# Define and compile your model architecture\n",
    "\n",
    "model=tf.keras.applications.VGG16(include_top=False)\n",
    "\n",
    "model_input=model.layers[0].input #acces to the input of the first layer\n",
    "model_output=model.layers[-2].output #acces to the output of the layer model.layers[-2]\n",
    "final_output=Dense(1,activation=\"linear\")(model_output)\n",
    "\n",
    "model=tf.keras.Model(inputs=model_input,outputs=final_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'], run_eagerly=True)\n",
    "\n",
    "model.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La difference aussi au niveau des performances de vgg et model1 cnn que j ai utilise et le dernier de github est l ajout des batch normalization\n",
    "#layers qui sont tres importants\n",
    "\n",
    "#9alab 3la downsampling rak chaftih f wa7ad l article o son role f rendre l entrainement plus fast et plus rapide\n",
    "#soit en entrainant moins de donnees ou en resizant vers image sghira bzaf ex 64 64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changing the learning rate in our sunset model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=3e-06>\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model(\"models\\\\model.04-3436.49.h5\")\n",
    "model.optimizer.learning_rate.assign(0.000003)\n",
    "optimizer = model.optimizer.learning_rate\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "1649/1649 [==============================] - 1498s 902ms/step - loss: 7588.9727 - mean_squared_error: 7588.9727 - val_loss: 14410.1650 - val_mean_squared_error: 14410.1650\n",
      "Epoch 2/150\n",
      "1649/1649 [==============================] - 254s 153ms/step - loss: 5630.2148 - mean_squared_error: 5630.2148 - val_loss: 10453.2100 - val_mean_squared_error: 10453.2100\n",
      "Epoch 3/150\n",
      "1649/1649 [==============================] - 261s 157ms/step - loss: 5431.3384 - mean_squared_error: 5431.3384 - val_loss: 5833.9902 - val_mean_squared_error: 5833.9902\n",
      "Epoch 4/150\n",
      "1649/1649 [==============================] - 258s 156ms/step - loss: 5283.1948 - mean_squared_error: 5283.1948 - val_loss: 5746.0210 - val_mean_squared_error: 5746.0210\n",
      "Epoch 5/150\n",
      "1649/1649 [==============================] - 256s 154ms/step - loss: 5220.4927 - mean_squared_error: 5220.4927 - val_loss: 11648.7393 - val_mean_squared_error: 11648.7393\n",
      "Epoch 6/150\n",
      "  44/1649 [..............................] - ETA: 3:55 - loss: 4868.1338 - mean_squared_error: 4868.1338"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7140\\3913493091.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m    \u001b[1;31m# Fit the model and record the loss values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m    \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m    \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m    \u001b[0mval_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                 \u001b[1;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 )\n\u001b[0;32m   1145\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m             outputs = reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"first\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1313\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1314\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1315\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3690\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3691\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3692\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3694\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m                 \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[1;31m# Run backwards pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         \u001b[0mreturn_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1096\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 \u001b[0mreturn_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args)\u001b[0m\n\u001b[0;32m    135\u001b[0m         ):\n\u001b[0;32m    136\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_sync_on_read_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                 \u001b[0mraw_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                 \u001b[1;31m# Results need to be wrapped in a `tf.identity` op to ensure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;31m# correct execution order.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\metrics\\base_metric.py\u001b[0m in \u001b[0;36mresult_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[0mobj_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol_status\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             )\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mag_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         obj.result = types.MethodType(\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\metrics\\base_metric.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUM_OVER_BATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         ]:\n\u001b[1;32m--> 535\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide_no_nan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m             raise NotImplementedError(\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mdiv_no_nan\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1653\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"div_no_nan\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1654\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1655\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1656\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_no_nan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   2103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_dense_var_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2105\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_var_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1465\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1467\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munused_other\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mvalue\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    580\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mgen_resource_variable_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_copy_on_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[1;32m--> 695\u001b[1;33m           self.handle, self._dtype)\n\u001b[0m\u001b[0;32m    696\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 525\u001b[1;33m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0m\u001b[0;32m    526\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " #i can fit again si c est pas suffisant\n",
    "#cnn model github entire data used\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs=150\n",
    "\n",
    "#model=tf.keras.models.load_model(\"models\\\\model.03-3695.77.h5\")\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "    \n",
    "    # Fit the model and record the loss values\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=num_epochs,callbacks=my_callbacks,verbose=1)\n",
    "    train_loss.append(history.history['loss'])\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    \n",
    "    # Print the loss for the current epoch\n",
    "    print('Train Loss: {:.4f}'.format(train_loss[-1]))\n",
    "    print('Val Loss: {:.4f}'.format(val_loss[-1]))\n",
    "    \n",
    "    # Plot the loss evolution\n",
    "    plt.plot(np.arange(epoch+1), train_loss, label='Train Loss')\n",
    "    plt.plot(np.arange(epoch+1), val_loss, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#with open('training_history.pkl', 'wb') as file:\n",
    "#    pickle.dump(model.history, file)\n",
    "model.save(os.path.join('models','last_epoch_model.h5'))\n",
    "\n",
    "np.save('my_history.npy',model.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating another edited version of sunset model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 64, 64, 128)       24704     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 64, 64, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 64)        524352    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 16)        4112      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 16, 16, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 8, 8, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,128,913\n",
      "Trainable params: 2,128,497\n",
      "Non-trainable params: 416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the model architecture using tf.keras API\n",
    "num_filters = 8\n",
    "kernel_size = [3,3]\n",
    "pool_size = [2,2]\n",
    "strides = 2\n",
    "dense_size = 1024\n",
    "drop_rate = 0.5\n",
    "\n",
    "\n",
    "def sunset_model_edit():\n",
    "    ## input\n",
    "    ### input image logs with shape (64,64,24)\n",
    "    x_in = tf.keras.Input(shape=(64,64,3))\n",
    "\n",
    "    ## 1st convolution block\n",
    "    x = tf.keras.layers.Conv2D(128,[8,8],padding=\"same\",activation='relu')(x_in)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size, strides)(x)\n",
    "\n",
    "    ## 2nd convolution block\n",
    "    x = tf.keras.layers.Conv2D(64,[8,8],padding=\"same\",activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size, strides)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(16,[2,2],padding=\"same\",activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size, strides)(x)\n",
    "\n",
    "    \n",
    "\n",
    "    ## two fully connected nets\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(dense_size, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(drop_rate)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(drop_rate)(x)\n",
    "\n",
    "    ## regression to prediction target\n",
    "    y_out = tf.keras.layers.Dense(units=1,activation='linear')(x)\n",
    "\n",
    "    # construct the model\n",
    "    model = tf.keras.Model(inputs=x_in,outputs=y_out)\n",
    "\n",
    "    return model\n",
    "\n",
    "# show model architecture\n",
    "sunset_model_edit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling andd training the new version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "825/825 [==============================] - 193s 230ms/step - loss: 7881.2041 - mean_squared_error: 7881.2041 - val_loss: 29607.4805 - val_mean_squared_error: 29607.4805\n",
      "Epoch 2/150\n",
      "825/825 [==============================] - 192s 232ms/step - loss: 5388.8901 - mean_squared_error: 5388.8901 - val_loss: 15759.0732 - val_mean_squared_error: 15759.0732\n",
      "Epoch 3/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 5248.5850 - mean_squared_error: 5248.5850 - val_loss: 9581.1338 - val_mean_squared_error: 9581.1338\n",
      "Epoch 4/150\n",
      "825/825 [==============================] - 189s 229ms/step - loss: 5070.0952 - mean_squared_error: 5070.0952 - val_loss: 9988.1641 - val_mean_squared_error: 9988.1641\n",
      "Epoch 5/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4955.8896 - mean_squared_error: 4955.8896 - val_loss: 14850.7217 - val_mean_squared_error: 14850.7217\n",
      "Epoch 6/150\n",
      "825/825 [==============================] - 190s 229ms/step - loss: 4849.4434 - mean_squared_error: 4849.4434 - val_loss: 8550.6807 - val_mean_squared_error: 8550.6807\n",
      "Epoch 7/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4799.6782 - mean_squared_error: 4799.6782 - val_loss: 11800.1055 - val_mean_squared_error: 11800.1055\n",
      "Epoch 8/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4796.4102 - mean_squared_error: 4796.4102 - val_loss: 22977.4707 - val_mean_squared_error: 22977.4707\n",
      "Epoch 9/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4734.7603 - mean_squared_error: 4734.7603 - val_loss: 4500.7441 - val_mean_squared_error: 4500.7441\n",
      "Epoch 10/150\n",
      "825/825 [==============================] - 192s 233ms/step - loss: 4644.9214 - mean_squared_error: 4644.9214 - val_loss: 11856.6055 - val_mean_squared_error: 11856.6055\n",
      "Epoch 11/150\n",
      "825/825 [==============================] - 189s 228ms/step - loss: 4704.9014 - mean_squared_error: 4704.9014 - val_loss: 4772.6880 - val_mean_squared_error: 4772.6880\n",
      "Epoch 12/150\n",
      "825/825 [==============================] - 191s 232ms/step - loss: 4585.7495 - mean_squared_error: 4585.7495 - val_loss: 3929.3848 - val_mean_squared_error: 3929.3848\n",
      "Epoch 13/150\n",
      "825/825 [==============================] - 192s 232ms/step - loss: 4561.7617 - mean_squared_error: 4561.7617 - val_loss: 4865.6353 - val_mean_squared_error: 4865.6353\n",
      "Epoch 14/150\n",
      "825/825 [==============================] - 191s 232ms/step - loss: 4515.0596 - mean_squared_error: 4515.0596 - val_loss: 3695.6384 - val_mean_squared_error: 3695.6384\n",
      "Epoch 15/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4465.5239 - mean_squared_error: 4465.5239 - val_loss: 6572.4644 - val_mean_squared_error: 6572.4644\n",
      "Epoch 16/150\n",
      "825/825 [==============================] - 189s 228ms/step - loss: 4462.8579 - mean_squared_error: 4462.8579 - val_loss: 4941.9351 - val_mean_squared_error: 4941.9351\n",
      "Epoch 17/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4434.8223 - mean_squared_error: 4434.8223 - val_loss: 4415.9771 - val_mean_squared_error: 4415.9771\n",
      "Epoch 18/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4344.6338 - mean_squared_error: 4344.6338 - val_loss: 4161.1548 - val_mean_squared_error: 4161.1548\n",
      "Epoch 19/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4278.8555 - mean_squared_error: 4278.8555 - val_loss: 3517.2910 - val_mean_squared_error: 3517.2910\n",
      "Epoch 20/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4353.6948 - mean_squared_error: 4353.6948 - val_loss: 3866.5786 - val_mean_squared_error: 3866.5786\n",
      "Epoch 21/150\n",
      "825/825 [==============================] - 189s 228ms/step - loss: 4281.4409 - mean_squared_error: 4281.4409 - val_loss: 3707.6145 - val_mean_squared_error: 3707.6145\n",
      "Epoch 22/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4246.2754 - mean_squared_error: 4246.2754 - val_loss: 3838.0259 - val_mean_squared_error: 3838.0259\n",
      "Epoch 23/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4220.8423 - mean_squared_error: 4220.8423 - val_loss: 3654.1831 - val_mean_squared_error: 3654.1831\n",
      "Epoch 24/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4252.3145 - mean_squared_error: 4252.3145 - val_loss: 4520.1001 - val_mean_squared_error: 4520.1001\n",
      "Epoch 25/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4161.2500 - mean_squared_error: 4161.2500 - val_loss: 3953.8723 - val_mean_squared_error: 3953.8723\n",
      "Epoch 26/150\n",
      "825/825 [==============================] - 189s 229ms/step - loss: 4122.1621 - mean_squared_error: 4122.1621 - val_loss: 3652.5012 - val_mean_squared_error: 3652.5012\n",
      "Epoch 27/150\n",
      "825/825 [==============================] - 192s 232ms/step - loss: 4105.5347 - mean_squared_error: 4105.5347 - val_loss: 3539.6167 - val_mean_squared_error: 3539.6167\n",
      "Epoch 28/150\n",
      "825/825 [==============================] - 192s 232ms/step - loss: 4063.6892 - mean_squared_error: 4063.6892 - val_loss: 3850.4460 - val_mean_squared_error: 3850.4460\n",
      "Epoch 29/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4034.3689 - mean_squared_error: 4034.3689 - val_loss: 8658.1553 - val_mean_squared_error: 8658.1553\n",
      "Epoch 30/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 4055.9751 - mean_squared_error: 4055.9751 - val_loss: 3891.4551 - val_mean_squared_error: 3891.4551\n",
      "Epoch 31/150\n",
      "825/825 [==============================] - 189s 228ms/step - loss: 3948.8044 - mean_squared_error: 3948.8044 - val_loss: 6904.2285 - val_mean_squared_error: 6904.2285\n",
      "Epoch 32/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 3947.8362 - mean_squared_error: 3947.8362 - val_loss: 3974.2815 - val_mean_squared_error: 3974.2815\n",
      "Epoch 33/150\n",
      "825/825 [==============================] - 191s 232ms/step - loss: 3926.3259 - mean_squared_error: 3926.3259 - val_loss: 7892.2725 - val_mean_squared_error: 7892.2725\n",
      "Epoch 34/150\n",
      "825/825 [==============================] - 192s 232ms/step - loss: 3883.9395 - mean_squared_error: 3883.9395 - val_loss: 4972.8765 - val_mean_squared_error: 4972.8765\n",
      "Epoch 35/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 3878.0396 - mean_squared_error: 3878.0396 - val_loss: 4444.6758 - val_mean_squared_error: 4444.6758\n",
      "Epoch 36/150\n",
      "825/825 [==============================] - 189s 228ms/step - loss: 3805.5674 - mean_squared_error: 3805.5674 - val_loss: 4191.2485 - val_mean_squared_error: 4191.2485\n",
      "Epoch 37/150\n",
      "825/825 [==============================] - 191s 231ms/step - loss: 3813.7368 - mean_squared_error: 3813.7368 - val_loss: 3617.1594 - val_mean_squared_error: 3617.1594\n",
      "Epoch 38/150\n",
      "825/825 [==============================] - 192s 232ms/step - loss: 3799.3125 - mean_squared_error: 3799.3125 - val_loss: 4568.7710 - val_mean_squared_error: 4568.7710\n",
      "Epoch 39/150\n",
      "825/825 [==============================] - 192s 232ms/step - loss: 3752.6895 - mean_squared_error: 3752.6895 - val_loss: 3573.9578 - val_mean_squared_error: 3573.9578\n",
      "Epoch 40/150\n",
      "544/825 [==================>...........] - ETA: 1:01 - loss: 3742.4792 - mean_squared_error: 3742.4792"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17768\\4006321688.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m ]\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel_sunset_edit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_callbacks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#i can fit again si c est pas suffisant\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#cnn model github entire data used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                 \u001b[1;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 )\n\u001b[0;32m   1145\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m             outputs = reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"first\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1313\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1314\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1315\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3690\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3691\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3692\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3694\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m                 \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    992\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[1;31m# Run backwards pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mx\u001b[0m  \u001b[1;31m# The default implementation does not use `x`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m         return self.compiled_loss(\n\u001b[1;32m-> 1053\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization_losses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m         )\n\u001b[0;32m   1055\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\compile_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch_dtype_and_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[0msw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m             \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0mtotal_loss_mean_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\losses.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    157\u001b[0m             )\n\u001b[0;32m    158\u001b[0m             return losses_utils.compute_weighted_loss(\n\u001b[1;32m--> 159\u001b[1;33m                 \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m             )\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\losses_utils.py\u001b[0m in \u001b[0;36mcompute_weighted_loss\u001b[1;34m(losses, sample_weight, reduction, name)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;31m# Apply reduction function to the individual weighted losses.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_weighted_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minput_casted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;31m# Convert the result back to the input type.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\losses_utils.py\u001b[0m in \u001b[0;36mreduce_weighted_loss\u001b[1;34m(weighted_losses, reduction)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mReductionV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUM_OVER_BATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_num_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\losses_utils.py\u001b[0m in \u001b[0;36m_safe_mean\u001b[1;34m(losses, num_present)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0mthen\u001b[0m \u001b[0mzero\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \"\"\"\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide_no_nan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_present\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_sum\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2312\u001b[0m   return reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[1;32m-> 2313\u001b[1;33m                               _ReductionDims(input_tensor, axis))\n\u001b[0m\u001b[0;32m   2314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_ReductionDims\u001b[1;34m(x, axis)\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m       \u001b[1;31m# Otherwise, we rely on Range and Rank to do the right thing at run-time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mrange\u001b[1;34m(start, limit, delta, dtype, name)\u001b[0m\n\u001b[0;32m   2122\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2124\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_range\u001b[1;34m(start, limit, delta, name)\u001b[0m\n\u001b[0;32m   7731\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7732\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 7733\u001b[1;33m         _ctx, \"Range\", name, start, limit, delta)\n\u001b[0m\u001b[0;32m   7734\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7735\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_sunset_edit=sunset_model_edit()\n",
    "model_sunset_edit.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'], run_eagerly=True)\n",
    "\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 40, mode = 'auto'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(monitor='val_loss',mode='min',save_best_only=True,filepath=os.path.join(\"models\",'model.{epoch:02d}-{val_loss:.2f}.h5'))\n",
    "]\n",
    "\n",
    "model_sunset_edit.fit(train_ds, validation_data=val_ds, epochs=150,callbacks=my_callbacks) #i can fit again si c est pas suffisant\n",
    "#cnn model github entire data used\n",
    "\n",
    "#with open('training_history.pkl', 'wb') as file:\n",
    "#    pickle.dump(model.history, file)\n",
    "model.save(os.path.join('models','last_epoch_model.h5'))\n",
    "\n",
    "np.save('my_history.npy',model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "825/825 [==============================] - 1537s 2s/step - loss: 8601.9619 - mean_squared_error: 8601.9619 - val_loss: 4323.4526 - val_mean_squared_error: 4323.4526\n",
      "Epoch 2/150\n",
      "825/825 [==============================] - 96s 116ms/step - loss: 5514.7759 - mean_squared_error: 5514.7759 - val_loss: 5256.4746 - val_mean_squared_error: 5256.4746\n",
      "Epoch 3/150\n",
      "825/825 [==============================] - 92s 111ms/step - loss: 5162.6533 - mean_squared_error: 5162.6533 - val_loss: 3885.3369 - val_mean_squared_error: 3885.3369\n",
      "Epoch 4/150\n",
      "825/825 [==============================] - 92s 111ms/step - loss: 5140.0186 - mean_squared_error: 5140.0186 - val_loss: 3589.1936 - val_mean_squared_error: 3589.1936\n",
      "Epoch 5/150\n",
      "825/825 [==============================] - 92s 111ms/step - loss: 4925.8369 - mean_squared_error: 4925.8369 - val_loss: 4513.0938 - val_mean_squared_error: 4513.0938\n",
      "Epoch 6/150\n",
      "825/825 [==============================] - 93s 112ms/step - loss: 4862.7061 - mean_squared_error: 4862.7061 - val_loss: 4963.8335 - val_mean_squared_error: 4963.8335\n",
      "Epoch 7/150\n",
      "825/825 [==============================] - 94s 113ms/step - loss: 4910.1035 - mean_squared_error: 4910.1035 - val_loss: 9749.8418 - val_mean_squared_error: 9749.8418\n",
      "Epoch 8/150\n",
      "825/825 [==============================] - 92s 111ms/step - loss: 4779.8433 - mean_squared_error: 4779.8433 - val_loss: 3945.4658 - val_mean_squared_error: 3945.4658\n",
      "Epoch 9/150\n",
      "825/825 [==============================] - 92s 111ms/step - loss: 4755.1875 - mean_squared_error: 4755.1875 - val_loss: 7312.9912 - val_mean_squared_error: 7312.9912\n",
      "Epoch 10/150\n",
      " 88/825 [==>...........................] - ETA: 1:18 - loss: 4806.6680 - mean_squared_error: 4806.6680"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17768\\1276579324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_callbacks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#i can fit again si c est pas suffisant\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#cnn model github entire data used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#with open('training_history.pkl', 'wb') as file:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#    pickle.dump(model.history, file)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                 \u001b[1;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1143\u001b[0m                     \u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjit_compile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_retracing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 )\n\u001b[1;32m-> 1145\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m             outputs = reduce_per_replica(\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    750\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Stagiaire_2023_Saad\\Working space\\saadenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3011\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m   3012\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"IteratorGetNext\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3013\u001b[1;33m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[0;32m   3014\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3015\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=150,callbacks=my_callbacks) #i can fit again si c est pas suffisant\n",
    "#cnn model github entire data used\n",
    "\n",
    "#with open('training_history.pkl', 'wb') as file:\n",
    "#    pickle.dump(model.history, file)\n",
    "model.save(os.path.join('models','last_epoch_model.h5'))\n",
    "\n",
    "np.save('my_history.npy',model.history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
